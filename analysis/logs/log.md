Weekly/Bi-Weekly Log
Date:
Week 1 — March 28, 2025

Number of hours:
~22 hours

Rose:
I led the drafting of the Executive Summary and Project Summary, laying the groundwork for our documentation. This process allowed me to clearly define the research motivation, the gap we aim to fill in humor-driven comment analysis, and our project's impact on educational content strategy. Collaborating with the team during initial planning was energizing.

Bud:
I'm looking forward to structuring the engagement metrics framework—particularly how we’ll quantify virality patterns and joke influence on audience behavior. It’s an exciting opportunity to create real-world value through data insights.

Thorn:
Balancing clarity with technical accuracy in the documentation was a bit challenging, especially when summarizing both NLP and ML models in non-technical terms. I also noticed some early inconsistencies in writing style across sections that needed editing for tone and flow.

Additional thought
I want to start building a reusable report structure now so future iterations are easier. If done well, our report could become a standard for analyzing humor in digital education content.


-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------


Weekly/Bi-Weekly Log
Date:
Week 2 — April 4, 2025

Number of hours:
~23 hours

Rose:
This week, I contributed to the signed proposal and finalized the milestone planning section. It was satisfying to translate our conceptual ideas into concrete, trackable phases. I also helped standardize the documentation process for better team collaboration.

Bud:
Excited to dive into the data visualization layer in the coming weeks, especially how we represent joke distribution and its relation to engagement. Also eager to contribute to stretch goals, particularly the emoji and hashtag processing module.

Thorn:
One issue was refining how we track engagement causality—i.e., confirming if joke comments truly influence viewer metrics or if they're just correlated. That insight will be key but tough to validate with limited metadata from YouTube’s API.

Additional thought
I’ll need to work closely with the rest of the team to avoid redundant efforts and ensure everyone’s models align with our documentation and evaluation metrics.


-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------


Weekly/Bi-Weekly Log
Date:
Week 3 — April 11, 2025

Number of hours:
~21 hours

Rose:
I supported the integration of NLP components into our reporting pipeline. I started drafting the engagement metrics analysis plan, deciding how we’ll handle video views, likes, and replies over time. It was satisfying to see data begin to take shape.

Bud:
Looking forward to early visualization prototypes using matplotlib and Plotly. These visual summaries will help bring our joke behavior insights to life and guide our final presentation. Also preparing to lead the analysis report synthesis.

Thorn:
We encountered a challenge in measuring temporal engagement changes, especially when YouTube API restrictions limit historical comment metadata. This might affect how well we can execute stretch goals like temporal trend analysis.

Additional thought
We should include a “limitations” section in the report to transparently explain these technical constraints. Also, consider logging engagement metrics snapshots during scraping for richer temporal insights.


-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------


Weekly/Bi-Weekly Log
Date:
Week 4 — April 18, 2025

Number of hours:
~23 hours

Rose:
This week, I made strong progress on the project documentation and synthesized insights for the initial report draft. I contributed to reviewing model outputs and translating findings into digestible insights for the final report. Our visual engagement breakdown is beginning to tell a story.

Bud:
Next, I plan to polish the visual design of our analysis report and help finalize the data visualization section. I’m also planning a personal sprint to test the emoji-based humor detection, as it can significantly boost detection accuracy.

Thorn:
Ensuring consistency between model predictions and our report interpretation was tricky—especially when the joke classification confidence varied. We also need better error analysis to explain misclassifications in the report.

Additional thought
Before we wrap up the testing phase, I’ll prioritize reviewing all documentation for coherence. I also want to explore building a demo interface to showcase the tool’s joke/sentiment breakdown live during the iShowcase.
